---
layout: post
title: "ç”¨ Matlab è®­ç»ƒä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ"
tags: ["ç¥ç»ç½‘ç»œ", "åˆ†ç±»å™¨", "NN", "Neural Network"]
menu: true
---

æŠ±ç€çº¯å±ç©ç¥¨çš„å¿ƒæ€çœ‹å®Œäº† [Andrew Ng çš„æœºå™¨å­¦ä¹ å…¥é—¨è¯¾](https://www.coursera.org/learn/machine-learning)ï¼Œåˆæ°é€¢æœŸæœ«è¯¾è®¾ï¼Œå°±æƒ³ç€åˆ©ç”¨ç¥ç»ç½‘ç»œåšä¸€ä¸ªç®€å•æ•°å­¦è¡¨è¾¾å¼çš„è¯†åˆ«å’Œæ±‚å€¼å·¥å…·ï¼Œä¸»è¦çš„æ¨¡å‹è®­ç»ƒå’Œè¯†åˆ«éƒ¨åˆ†éƒ½æ˜¯ç”± Matlab å®Œæˆã€‚

## ç¥ç»ç½‘ç»œæ¨¡å‹

![æ¨¡å‹ç®€åŒ–å›¾](//wil.dog/static/images/nn-model.png)

è€ƒè™‘åˆ°è®¡ç®—é€Ÿåº¦ï¼Œæˆ‘åªå»ºç«‹äº†ä¸€ä¸ªç®€å•çš„ä¸‰å±‚ BP ç¥ç»ç½‘ç»œæ¨¡å‹ä½œä¸ºåˆ†ç±»å™¨æ¥è¯†åˆ«å•ä¸ªå­—ç¬¦ï¼Œæ¨¡å‹ç®€åŒ–å›¾å¦‚ä¸Šã€‚è¾“å…¥å±‚æ˜¯ç”± 20x20 çš„å›¾åƒå¾—åˆ°çš„ 1x400 çš„ç‰¹å¾å‘é‡ï¼Œéšè—å±‚å…± 80 ä¸ªéšè—å•å…ƒï¼Œæ¿€æ´»å‡½æ•°é‡‡ç”¨ sigmoid functionï¼Œè¾“å‡ºå±‚æ˜¯ä¸€ä¸ª 1x17 çš„å‘é‡ï¼Œå¯ä»¥ç”¨æ¥æè¿° 17 ç§è¯†åˆ«ç»“æœï¼š`æ•°å­— 0-9 å’Œ +, -, â¨¯, Ã·, ^, (, )`ã€‚

## æ•°æ®é›†å’Œé¢„å¤„ç†

* åŒæ ·ä¹Ÿæ˜¯å‡ºäºè®¡ç®—é€Ÿåº¦çš„è€ƒè™‘ï¼Œä»¥åŠéœ€è¦è¯†åˆ«çš„é™¤äº†æ•°å­—è¿˜æœ‰ç¬¦å·ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨åªå«æ•°å­—ä¸”è¾ƒå¤§çš„ [MNIST æ•°æ®é›†](http://yann.lecun.com/exdb/mnist/)ï¼Œè€Œæ˜¯æ‰¾å®¤å‹ä¸€èµ·æ‰‹å†™äº†å¤§æ¦‚ 1000 ä¸ªæ•°å­—å’Œç¬¦å·ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚

* ä¸ç®¡æ˜¯ç”¨ä½œè®­ç»ƒæ•°æ®çš„å›¾åƒè¿˜æ˜¯æœ€ç»ˆéœ€è¦è¯†åˆ«çš„å›¾åƒéƒ½éœ€è¦åšé¢„å¤„ç†ï¼ŒæŠŠå›¾ç‰‡ä¸Šè¡¨è¾¾å¼çš„æ¯ä¸ªå­—ç¬¦åˆ†ç¦»æˆå•ç‹¬çš„å›¾åƒå†ä¾æ¬¡é€è‡³åˆ†ç±»å™¨è¯†åˆ«ï¼Œé¢„å¤„ç†ä¹Ÿæ˜¯ç”¨ Matlab å®Œæˆï¼Œå…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š

    1. å›¾åƒè½¬ä¸ºç°åº¦å›¾åƒååè‰²å¤„ç†ï¼Œå¹¶è¿›è¡Œä¸­å€¼æ»¤æ³¢ä»¥å¹³æ»‘å›¾åƒï¼Œç„¶åè¿›è¡Œæ•´ä½“[è¾¹ç•Œé™å®š](https://github.com/Wildog/handwritten-expr-evaluator/blob/master/xylimit.m)ï¼Œæˆªå–è¡¨è¾¾å¼åŒºåŸŸå›¾åƒã€‚![](//wil.dog/static/images/img-preprocess-1.png)
    2. æ¨ªå‘æå–å¹¶æ‹¼æ¥æœ‰æ•ˆè¡Œï¼Œçºµå‘æå–å¹¶åˆ†å‰²æœ‰æ•ˆå­—ç¬¦ã€‚æå–æ¯ä¸ªåˆ†å‰²åŒºåŸŸä¸ºç‹¬â½´å›¾åƒï¼Œè¿›è¡Œè¾¹ç•Œé™å®šï¼Œè®¡ç®—ç°åº¦é˜ˆå€¼å¹¶è½¬ä¸ºâ¼†å€¼å›¾åƒï¼Œæœ€åå¤§å°å½’ä¸€åŒ–å›¾åƒï¼šå¡«å……è‡³æ­£æ–¹å½¢å¹¶ç»Ÿä¸€ä¸º 20x20 çš„å›¾åƒã€‚![](//wil.dog/static/images/img-preprocess-2.png)
    
    é¢„å¤„ç†éƒ¨åˆ†è¿˜éœ€è¦æ³¨æ„çš„ä¸»è¦é—®é¢˜æ˜¯è¿‡æ»¤å™ªéŸ³ï¼Œé™¤äº†å¹³æ»‘å›¾åƒå’Œè¾¹ç•Œé™å®šä»¥å¤–ï¼Œè¿˜è¦å‰”é™¤æ‰é«˜åº¦è¿‡å°çš„è¡Œã€å®½åº¦è¿‡å°çš„åˆ—ä»¥åŠé¢ç§¯è¿‡å°çš„åŒºåŸŸã€‚å®Œæ•´ä»£ç è§è¿™é‡Œï¼š[https://github.com/Wildog/handwritten-expr-evaluator/blob/master/getPicChar.m](https://github.com/Wildog/handwritten-expr-evaluator/blob/master/getPicChar.m)

## è®­ç»ƒæ¨¡å‹

* é¦–å…ˆæ˜¯éšæœºåˆå§‹åŒ–æƒé‡ï¼Œé¿å…æ¯å±‚çš„æ¯ä¸ªå•å…ƒå­¦ä¹ åˆ°åŒæ ·çš„å‚æ•°ã€‚æœ¬è´¨å°±æ˜¯ç»™æ¯ä¸ªæƒé‡çŸ©é˜µé‡Œé¢çš„æ¯ä¸ªæƒé‡è®¾ç½®ä¸€ä¸ªä»‹äº [-ğœº, ğœº] çš„å€¼ï¼Œè¿™ä¸ª ğœº ä¸€èˆ¬å– `sqrt(6) / sqrt(input_layer_size + output_layer_size)`ï¼Œå®Œæ•´å‡½æ•°å¦‚ä¸‹ï¼š

{% highlight matlab %}
function W = randInitializeWeights(L_in, L_out)
% ç”±äº bias unit çš„å­˜åœ¨ï¼Œæƒé‡çŸ©é˜µçš„å®é™…å¤§å°æ˜¯ L_out * (1 + L_in)
W = zeros(L_out, 1 + L_in);
epsilon_init = sqrt(6) / sqrt(L_in + L_out);
W = rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init;
{% endhighlight %}

* è®­ç»ƒæ¨¡å‹çš„æœ¬è´¨å°±æ˜¯ä¸æ–­åœ°è¿­ä»£å­¦ä¹ åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•æœ€å°åŒ–ä»£ä»·å‡½æ•°ã€‚åœ¨æ¯è½®è¿­ä»£ä¸­ï¼Œå…ˆä½¿ç”¨å‰å‘ä¼ æ’­ç®—æ³•è®¡ç®—å„å±‚è¾“å‡ºå€¼ï¼Œå†ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•è®¡ç®—å„å±‚æ®‹å·®ä»¥è®¡ç®—å„ä¸ªæƒé‡çŸ©é˜µçš„æ¢¯åº¦ï¼Œå¹¶è®¡ç®—ä»£ä»·å‡½æ•°ï¼Œæˆ‘å†™çš„ä¸€è½®è¿­ä»£å¦‚ä¸‹ï¼š

{% highlight matlab %}
function [J grad] = nnCostFunction(nn_params, ...
                                   input_layer_size, ...
                                   hidden_layer_size, ...
                                   num_labels, ...
                                   X, y, lambda)

Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ...
                 hidden_layer_size, (input_layer_size + 1));

Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ...
                 num_labels, (hidden_layer_size + 1));

m = size(X, 1);
         
J = 0;
Theta1_grad = zeros(size(Theta1));
Theta2_grad = zeros(size(Theta2));

for i = 1:m
    %Forward Propagation ç®—æ³•è®¡ç®—å„å±‚è¾“å‡ºå€¼
    hidden_layer = zeros(hidden_layer_size,1);
    input_layer = [1; X(i,:)'];
    hidden_layer = [1; sigmoid(Theta1 * input_layer)];
    output_layer = zeros(num_labels,1);
    output_layer = sigmoid(Theta2 * hidden_layer);
    y_recode = zeros(num_labels,1);
    y_recode(y(i)) = 1;
    %Backpropagation ç®—æ³•è®¡ç®—å„å±‚æ®‹å·®ä»¥è®¡ç®— Theta1 å’Œ Theta2 çš„æ¢¯åº¦
    delta3 = output_layer - y_recode;
    delta2 = Theta2' * delta3 .* (hidden_layer .* (1 - hidden_layer));
    delta2 = delta2(2:end); %!!!ä¸¢å¼ƒ bias unit
    %ç´¯åŠ æ¢¯åº¦
    Theta1_grad = Theta1_grad + delta2 * input_layer';
    Theta2_grad = Theta2_grad + delta3 * hidden_layer';
    %ç´¯åŠ  LR cost
    J = J + y_recode' * log(output_layer) + (1 - y_recode') * log(1 - output_layer);
end

%è®¡ç®— NN cost
J = -(1/m) * J + lambda/(2*m) * (sum(sum(Theta1(:, 2:end).^2)) + sum(sum(Theta2(:, 2:end).^2)));

Theta1_temp = Theta1_grad;
Theta1_grad = (1/m) * Theta1_grad + (lambda/m) * Theta1;
tmp1 = ((1/m) * Theta1_temp);
Theta1_grad(:,1) = tmp1(:,1);

Theta2_temp = Theta2_grad;
Theta2_grad = (1/m) * Theta2_grad + (lambda/m) * Theta2;
tmp2 = ((1/m) * Theta2_temp);
Theta2_grad(:,1) = tmp2(:,1);

grad = [Theta1_grad(:) ; Theta2_grad(:)];
{% endhighlight %}

è¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä¸€è½®è¿­ä»£åçš„ä»£ä»·å‡½æ•°å€¼å’Œå„ä¸ªæƒé‡çŸ©é˜µçš„æ¢¯åº¦ï¼Œç»™è¿™ä¸ªå‡½æ•°åˆ›å»ºä¸€ä¸ªå¥æŸ„ï¼Œè®¾ç½®ä¸€ä¸‹å­¦ä¹ ç‡å’Œæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå’Œéšæœºåˆå§‹åŒ–åçš„å„æƒé‡çŸ©é˜µä¸€èµ·ä¼ ç»™ [fmincg å‡½æ•°](https://github.com/Wildog/handwritten-expr-evaluator/blob/master/fmincg.m)è®¡ç®—ï¼Œç„¶åé™é™åœ°ç­‰ç€ä»£ä»·å‡½æ•°æ”¶æ•›å°±è¡Œäº†ï¼Œä¸æ–­çš„æµ‹è¯•å‡†ç¡®ç‡å†åå¤æ›´æ”¹å‚æ•°é‡æ–°è®­ç»ƒï¼Œæœ€åå¾—åˆ°æ»¡æ„çš„å„æƒé‡çŸ©é˜µã€‚

## å¤§åŠŸå‘Šæˆ

å¾—åˆ°æœ€ç»ˆçš„æƒé‡çŸ©é˜µåï¼Œé’ˆå¯¹é¢„å¤„ç†åçš„æ¯ä¸ªå­—ç¬¦å›¾åƒçš„åƒç´ çŸ©é˜µè®¡ç®—å…¶è¾“å‡ºå±‚å°±å¯ä»¥è¯†åˆ«å‡ºå¯¹åº”çš„å­—ç¬¦äº†ï¼Œä¾æ¬¡è¯†åˆ«æ¯ä¸ªå­—ç¬¦æœ€ç»ˆå¾—åˆ°æ•´ä¸ªè¡¨è¾¾å¼ï¼Œå‰©ä¸‹çš„è®¡ç®—è¡¨è¾¾å¼çš„æ–¹æ³•å¤ªå¤šäº†ä¸å†å¤šæï¼Œæ™’ä¸‹ç»“æœå›¾ï¼š

![result](//wil.dog/static/images/nn-result.png)

å®Œæ•´é¡¹ç›®åœ°å€ï¼š[https://github.com/Wildog/handwritten-expr-evaluator](https://github.com/Wildog/handwritten-expr-evaluator)


